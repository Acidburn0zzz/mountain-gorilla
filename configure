#!/bin/bash
# vi: tabstop=4 expandtab shiftwidth=4
#
# Configure the mountain gorilla (aka SDC) build.
#
# "targets.json" is a mapping of Makefile target to info about that target.

if [ "$TRACE" != "" ]; then
    export PS4='${BASH_SOURCE}:${LINENO}: '
    set -o xtrace
fi
set -o errexit
set -o pipefail

#---- config, globals

BRANCH=master
TRY_BRANCH=

ROOT=$(pwd)
MG_CACHE_DIR=${ROOT}/cache

# Username and password filled by `ensure_bits_credentials`.
BITS_USERNAME=
BITS_PASSWORD=
BITS_PROTO=https
BITS_HOST=bits.joyent.us
BITS_BASE_PATH=/builds

# This is a HACK to figure out if we're in the bh1 lab (assume we are if
# the IP is 10.2.X.X) so that we can switch the Bits url to an IP because
# the URL doesn't work in the lab.
if [[ $(uname -s) == "SunOS" && \
      $(sysinfo -p | grep "Network_Interface.*IPv4_Address=" \
        | cut -d "'" -f2 | grep 10\.2\. | wc -l | tr -d ' ') -gt 0 ]]; then
    # Assume we're in the BH-1 lab.
    echo "# Looks like we're in the BH-1 lab, use internal IPs for BITS_HOST."
    if [[ "$(echo $BITS_HOST | cut -d. -f1)" == "stuff" ]]; then
        BITS_HOST=10.2.0.190
    elif [[ "$(echo $BITS_HOST | cut -d. -f1)" == "bits" ]]; then
        network=$(sysinfo | json "Virtual Network Interfaces".net0.ip4addr | cut -d '.' -f1-3)
        if [[ "$network" == "10.2.172" ]]; then
            BITS_HOST=10.2.172.96
        else
            BITS_HOST=10.2.0.21
        fi
    fi
fi

if [[ $(uname -s) == "SunOS" ]]; then
    MTIME='stat -c %Z'
else
    MTIME='stat -f %m'
fi

# GNU cp has '--link'.
if [[ -x `which gcp` ]]; then
    CP_LINK="gcp --link"
else
    CP_LINK=$((cp --version 2>/dev/null | grep GNU >/dev/null) && echo "cp --link" || echo "cp")
fi
CURL="curl --fail --connect-timeout 10 -s"



#---- internal support functions

function fatal {
    echo "$(basename $0): error: $1"
    exit 1
}

function errexit {
    [[ $1 -ne 0 ]] || exit 0
    fatal "error exit status $1 at line $2"
}

function ensure_manta_credentials {
    if [[ -z "$MANTA_KEY_ID" ]]; then
        export MANTA_KEY_ID=`ssh-keygen -l -f ~/.ssh/id_rsa.pub | awk '{print $2}' | tr -d '\n'`
    fi
    export MANTA_URL=https://us-east.manta.joyent.com
    if [[ -z "$MANTA_USER" ]]; then
        export MANTA_USER="Joyent_Dev";
    fi
    export manta_base_path="/Joyent_Dev/stor/builds"
}

function ensure_bits_credentials {
    MG_CONFIG_PATH=~/.sdcbuild.json
    if [[ -z "$BITS_USERNAME" ]]; then
        BITS_USERNAME=$(cat $MG_CONFIG_PATH | $JSON username)
    fi
    if [[ -z "$BITS_USERNAME" ]]; then
        fatal "Could not get 'username' from '$MG_CONFIG_PATH'."
    fi
    if [[ -z "$BITS_PASSWORD" ]]; then
        BITS_PASSWORD=$(cat $MG_CONFIG_PATH | $JSON password)
    fi
    if [[ -z "$BITS_PASSWORD" ]]; then
        fatal "Could not get 'password' from '$MG_CONFIG_PATH'."
    fi
}

# Blow away the bits cache once per-day because don't want it to grow
# unbounded in size (esp. for the continuous-build system). An alternative
# would be to put a size limit on it.
function flush_bits_cache() {
    if [[ -f $MG_CACHE_DIR/bits/created ]]; then
        local bits_cache_age=$((`date "+%s"` - `$MTIME $MG_CACHE_DIR/bits/created`))
        # One day in 86400. We use a bit more to avoid harmonics with
        # once-per-day builds.
        if [[ $bits_cache_age -gt 100000 ]]; then
            echo "# Bit cache '$MG_CACHE_DIR/bits' is more than a day old. Blowing it away to be recreated."
            rm -rf $MG_CACHE_DIR/bits
        fi
    fi
}


# Preload $MG_CACHE_DIR/bits/ with the latest built and uploaded bits for
# the given target and branch.
#
# Usage:
#   preload_bits_from_manta TARGET BRANCH TRY_BRANCH

# Example:
#   preload_bits smartlogin master ""
#   preload_bits release-20110901-upgrade/agents-upgrade master ""
#
function preload_bits_from_manta() {
    local target=$1
    local branch=$2
    local try_branch=$3
    local target_base=$(basename $target)
    # Don't bork if this was already preloaded by another target.
    if [[ -d bits/$target_base ]]; then
        return;
    fi
    echo ""
    echo "# preload 'bits/$target_base from Manta'"

    ensure_manta_credentials

    local target_mpath
    local target_branch=$(dirname $target)
    if [[ "$target_branch" != "." ]]; then
        branch=$target_branch
    fi
    target_mpath=${manta_base_path}/${target_base}/
    local best_branch=$try_branch
    if [[ -z $best_branch ]]; then
        best_branch="master"
    fi
    local latest_mpath=${target_mpath}/${best_branch}-latest
    local latest_dir=$(mget $latest_mpath 2> /dev/null)
    if [[ -z "$latest_dir" ]]; then
        best_branch="master"
        latest_mpath=${target_mpath}/${best_branch}-latest
        latest_dir=$(mget $latest_mpath 2> /dev/null)
    fi
    if [[ -z "$latest_dir" ]]; then
        fatal "Could not get latest dir for target $target"
    fi
    local dirs=$(mfind -t d $latest_dir)
    mkdir -p $MG_CACHE_DIR/bits/
    for dir in $dirs; do
        mkdir -p ${MG_CACHE_DIR}/bits/${dir#$manta_base_path}
    done
    local files=$(mfind -t o $latest_dir)
    for file in $files; do
        dir=$(dirname $file)
        if [[ "${file##*.}" == "manta" ]]; then
            local targetname=$(cat targets.json | json ${target}.image_name)
            local zfsfiles="$(mget -q $file | json -H -a image_path manifest_path)"
            local image=$(echo $zfsfiles | cut -d ' ' -f 1)
            local manifest=$(echo $zfsfiles | cut -d ' ' -f 2)
            local image_targ=$(echo $image | sed -e "s:$targetname:$target_base:g")
            local manifest_targ=$(echo $manifest | sed -e "s:$targetname:$target_base:g")
            (cd ${MG_CACHE_DIR}/bits/${dir#$manta_base_path};
                if [[ ! -f $(basename $image_targ) ]]; then mget -o $(basename $image_targ) $image; fi
                if [[ ! -f $(basename $manifest_targ) ]]; then mget -o $(basename $manifest_targ) $manifest; fi
            )
        else
            (cd ${MG_CACHE_DIR}/bits/${dir#$manta_base_path};
                mget -O $file)
        fi
    done

	# Copy over to bits dir.
    mkdir -p bits
    [[ -d "bits/$target_base" ]] && fatal "'bits/$target_base' already exists"
    $CP_LINK -PR ${MG_CACHE_DIR}/bits/${latest_dir#$manta_base_path}/$target_base bits/$(basename $target)

}


# Preload $MG_CACHE_DIR/bits/ with the latest built and uploaded bits for
# the given target and branch.
#
# Usage:
#   preload_bits TARGET BRANCH TRY_BRANCH
# where:
#   TARGET is one of:
#       (a) a string subdir of the https://bits.joyent.com/builds
#           builds repo;
#       (b) a "$target_branch/$subdir" that specifies an alternative branch
#           just for this target ; or
#       (b) a full path to such a dir. This must be a URL dir
#           that serves Apache/Nginx-index-style directories.
#
# Example:
#   preload_bits smartlogin master ""
#   preload_bits release-20110901-upgrade/agents-upgrade master ""
#   preload_bits http://download.joyent.com/pub/build/sdcnode master ""
#
function preload_bits() {

    if [[ -n $USE_MANTA && "$(basename $1)" != "sdcnode" ]]; then
        preload_bits_from_manta $@
        return 0
    fi
    local target=$1
    local branch=$2
    local try_branch=$3
    local target_base=$(basename $target)

    # Don't bork if this was already preloaded by another target.
    if [[ -d bits/$target_base ]]; then
        return;
    fi

    echo ""
    echo "# preload 'bits/$target_base'"

    ensure_bits_credentials

    local target_url
    local target_url_censor
    if [[ $(echo $target | cut -c 1-4) == "http" ]]; then
        target_url=$target
        if [[ "${target_url:(-1)}" != "/" ]]; then
            target_url=$target_url/
        fi
        target_url_censor=$target_url
    else
        # If a "target_branch" is specified, switch to that.
        local target_branch=$(dirname $target)
        if [[ "$target_branch" != "." ]]; then
            branch=$target_branch
        fi

        local bits_url=$BITS_PROTO://$BITS_USERNAME:$BITS_PASSWORD@$BITS_HOST$BITS_BASE_PATH
        local bits_url_censor=$BITS_PROTO://$BITS_USERNAME:*password*@$BITS_HOST$BITS_BASE_PATH
        if [[ "${bits_url:(-1)}" != "/" ]]; then
            bits_url=$bits_url/
        fi
        if [[ "${bits_url_censor:(-1)}" != "/" ]]; then
            bits_url_censor=$bits_url_censor/
        fi
        target_url=$bits_url$target_base/
        target_url_censor=$bits_url_censor$target_base/
    fi
    local_cache_reldir=${target_url#*://}
    local_cache_reldir=${local_cache_reldir#*@}

    # Branch dir: try $try_branch, then $branch.
    local best_branch=$try_branch
    local latest_url=$target_url$try_branch-latest/
    if [[ -z "$best_branch" ||
          $($CURL -kI $latest_url | head -1 | awk '{print $2}') != "200" ]]; then
        best_branch=$branch
        latest_url=$target_url$branch-latest/
        if [[ $($CURL -kIS $latest_url | head -1 | awk '{print $2}') != "200" ]]; then
            fatal "'$target_url_censor/$branch-latest/' does not exist"
        fi
    fi
    echo "# use branch '$best_branch'"

    # Find the latest build time for this branch.
    local latest_build=$($CURL -Sk $target_url \
        | grep "href=\"" \
        | cut -d'"' -f2 \
        | grep "^$best_branch-" \
        | grep -v -- '-latest/$' \
        | sort \
        | tail -1)
    local local_cache_dir=$MG_CACHE_DIR/bits/$local_cache_reldir$latest_build$target_base

    if [[ -d $local_cache_dir ]]; then
        echo "# local cache at '$local_cache_dir' already exists"
    else
        # Mark creation for bits cache flush every day.
        mkdir -p $MG_CACHE_DIR/bits
        if [[ ! -f $MG_CACHE_DIR/bits/created ]]; then
            touch $MG_CACHE_DIR/bits/created
        fi

        latest_url=$target_url$latest_build
        local latest_url_censor=$target_url_censor$latest_build

        # Update cache in $MG_CACHE_DIR/bits
        # `-l 2`: Two levels deep needed for 2-level depth of 'agents' bits area.
        echo "# download from $latest_url_censor"
        (cd $MG_CACHE_DIR/bits \
            && wget -q -np -l 2 --no-check-certificate -r -L -R 'index.html,*.log' \
                $latest_url$target_base/)
    fi
    local md5sums_path=$local_cache_dir/../md5sums.txt
    if [[ ! -f $md5sums_path ]]; then
        $CURL -Sk ${latest_url}md5sums.txt -o $md5sums_path
    fi

    # MD5 check of downloaded bits.
    for bit in $(cd $local_cache_dir/../ && find . -type f | grep -v md5sums.txt); do
        local correct_md5=$(grep $bit $md5sums_path | cut -d ' ' -f1)
        local actual_md5=$(openssl dgst -md5 < $local_cache_dir/../$bit | awk '{print $NF}')
        if [[ $correct_md5 != $actual_md5 ]]; then
            rm $local_cache_dir/../$bit
            fatal "md5 check failure on $local_cache_dir/../$bit (actual '$actual_md5', from md5sums '$correct_md5')"
        fi
    done

    # Copy over to bits dir.
    mkdir -p bits
    [[ -d "bits/$target_base" ]] && fatal "'bits/$target_base' already exists"
    $CP_LINK -PR $local_cache_dir bits/$target_base
}

# Clone/update the given git repo in the repo cache.
# Usage:
#   get_repo_cache REPO-URL REPO-DIR SUBMODULE-UPDATE
# Example:
#   get_repo_cache git@git.joyent.com:smart-login.git smart-login true
function get_repo_cache() {
    local repo_url=$1
    local repo_dir=$2
    local dst_dir=$MG_CACHE_DIR/repos/$repo_dir

    if [[ ! -d "$MG_CACHE_DIR/repos/$repo_dir" ]]; then
        mkdir -p $MG_CACHE_DIR/repos
        local tmp_dir=$MG_CACHE_DIR/repos/.tmp.$repo_dir
        rm -rf $tmp_dir
        git clone $repo_url $tmp_dir
        mv $tmp_dir $MG_CACHE_DIR/repos/$repo_dir
    else
        (cd $MG_CACHE_DIR/repos/$repo_dir; git pull)
    fi
    if [[ "$submodule_update" == "true" ]]; then
        (cd $MG_CACHE_DIR/repos/$repo_dir; git submodule update --init --recursive)
    fi

    # Error out if the cached repo is dirty. These thigns should always
    # be pristine.
    if [[ "$(cd $MG_CACHE_DIR/repos/$repo_dir && git describe --all --dirty | grep dirty)" != "" ]]; then
        fatal "Repo '$repo_dir' cache, $MG_CACHE_DIR/repos/$repo_dir, is dirty!"
    fi
}


# Get the requested repo.
# Usage:
#   get_repo2 REPO-URL BRANCH SUBMODULE-UPDATE [NAME] [TRY-BRANCH]
#
# If "SUBMODULE-UPDATE" is "true", then "git submodule update ..." is
# used on the repo.
#
# If "NAME" is given, that subdir under "build/" will be used as the
# clone dir. Else it is inferred from the REPO-URL.
#
function get_repo2() {
    local repo_url=$1
    local branch=$2
    local submodule_update=$3
    local repo_dir=$4
    local try_branch=$5

    if [[ -z "$repo_dir" ]]; then
        repo_dir=${repo_url##*/}    # strip to last '/'
        repo_dir=${repo_dir##*:}    # strip to last ':'
        repo_dir=${repo_dir%*.git}    # strip '.git' at tail
    fi

    echo "# get '$repo_url' to repo cache ($MG_CACHE_DIR/repos)"
    get_repo_cache ${repo_url} ${repo_dir} ${submodule_update}

    echo "# copy '$MG_CACHE_DIR/repos/$repo_dir' to 'build/$repo_dir'"
    mkdir -p build
    cp -PR $MG_CACHE_DIR/repos/$repo_dir build/$repo_dir
    (cd build/$repo_dir ; git checkout $branch)

    if [[ ! -z "$try_branch" ]]; then
        (cd build/$repo_dir ; git checkout $try_branch && git pull || true)
    fi
    if [[ "$submodule_update" == "true" ]]; then
        (cd build/$repo_dir; git submodule update --init --recursive)
    fi
}

function gen_config() {
    local output
    mkdir -p bits
    cat <<EOF >bits/config.mk
TIMESTAMP=$(TZ=UTC date "+%Y%m%dT%H%M%SZ")
BRANCH=$BRANCH
TRY_BRANCH=$TRY_BRANCH
MG_NODE=$MG_NODE
MG_CACHE_DIR=$(cd $MG_CACHE_DIR >/dev/null; pwd)

EOF
  mkdir -p build
  for repo in $(ls -1 build/); do
      repo_mk_name=$(echo $repo | tr [:lower:] [:upper:] | tr - _)
      branch_name=$((cd build/${repo} && git symbolic-ref HEAD 2> /dev/null ) || echo "")
      echo ${repo_mk_name}_BRANCH=$(echo ${branch_name##refs/heads/} || echo "") >> ${ROOT}/bits/config.mk
      echo ${repo_mk_name}_SHA=$((cd build/${repo} && git log --pretty=format:'%h' -1 ) || echo "") >> ${ROOT}/bits/config.mk
  done

  # Makefile vars for appliance builds (i.e. the "foo_image" targets).
  for targ in $TARGETS; do
      targ_mk_name=$(echo $targ | tr [:lower:] [:upper:] | tr - _)
      if [[ $(cat ${ROOT}/targets.json | $JSON ${targ} | $JSON appliance) == 'true' ]]; then
        echo ${targ_mk_name}_IMAGE_UUID=$(cat ${ROOT}/targets.json | $JSON ${targ}.image_uuid) >> ${ROOT}/bits/config.mk
        echo ${targ_mk_name}_IMAGE_NAME=\"$(cat ${ROOT}/targets.json | $JSON ${targ}.image_name)\" >> ${ROOT}/bits/config.mk
        echo ${targ_mk_name}_IMAGE_DESCRIPTION=\"$(cat ${ROOT}/targets.json | $JSON ${targ}.image_description)\" >> ${ROOT}/bits/config.mk
        echo ${targ_mk_name}_PKGSRC=\"$(cat ${ROOT}/targets.json | $JSON ${targ}.pkgsrc | $JSON -a |  xargs)\" >> ${ROOT}/bits/config.mk
        local num_tarballs=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.length)
        local tarballs=""
        local index=0
        while [[ ${index} -lt ${num_tarballs} ]]; do
            local tb_name=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.${index}.name)
            local tb_tarball=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.${index}.tarball)
            [[ -z "$tb_tarball" ]] && fatal "no '$targ.tarballs.$index.tarball' in targets.json"
            tb_tarball=$ROOT/bits/$tb_tarball
            local tb_sysroot=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.${index}.sysroot)
            [[ -z "$tb_sysroot" ]] && fatal "no '$targ.tarballs.$index.sysroot' in targets.json"
            tarballs="$tarballs $tb_tarball:$tb_sysroot"
            index=$((${index} + 1))
        done
        echo ${targ_mk_name}_EXTRA_TARBALLS=\"${tarballs}\" >> ${ROOT}/bits/config.mk
      fi
  done
}


function print_help() {
    echo "Configure this SDC build. This involves cloning/pulling the "
    echo "component source repositories."
    echo ""
    echo "Usage:"
    echo "  ./configure [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  -h, --help   Print this help and exit."
    echo ""
    echo "  -n NODE_EXE  Path to node exe for MG to use."
    echo ""
    echo "  -b BRANCH    Branch to checkout. Defaults to 'master'."
    echo "               Note that this is for *all* core repositories."
    echo "  -B TRY-BRANCH"
    echo "               Branch to try to checkout (if it exists). '-b' value"
    echo "               is used as the default. This is useful for building"
    echo "               a feature branch on one of the many repos used for"
    echo "               a target."
    echo "  -t TARGET    Prepare to build only this target. Valid targets are"
    echo "               the keys of 'targets.json' plus a special value"
    echo "               'all-except-platform' to build all targets except the"
    echo "               slow-to-build platform."
    echo "  -r           Regenerate config.mk. This doesn't touch repos in"
    echo "               'build/' or preload in 'bits/'."
    echo "  -c CACHE-DIR Specify a cache directory. Default: './cache'."
    echo "               The cache is used for caching git clones, preloaded"
    echo "               bits and npm downloads. The 'bits cache' is"
    echo "               automatically removed if it is more than a day old."
    exit 0
}


function get_target_repos() {
    local target=$1
    local info
    for info in `cat targets.json | $JSON $target.repos | $JSON -a -d, url dir submodule-update`; do
        local repo_url=$(echo "$info" | cut -d, -f 1)
        local repo_dir=$(echo "$info" | cut -d, -f 2)
        local submodule_update=$(echo "$info" | cut -d, -f 3)
        [[ -z "$submodule_update" ]] && submodule_update=true
        get_repo2 $repo_url $BRANCH "$submodule_update" "$repo_dir" "$TRY_BRANCH"
    done
}

function get_pkgsrc() {
  if [[ -d ${ROOT}/build/usb-headnode ]]; then
    echo "# get pkgsrc packages for build/usb-headnode zones (to build/pkgsrc)"

    mkdir -p build/pkgsrc/

    set -o xtrace

    shopt -s extglob

    for dataset in $(find ${ROOT}/build/usb-headnode/zones -name "dataset"); do
      local ds=$(cat ${dataset})
      local pkgsrc_url=$((${JSON} datasets | ${JSON} -a name pkgsrc_url \
          | grep "$(basename ${ds%\.dsmanifest})" \
          | cut -d ' ' -f2) < ${ROOT}/build/usb-headnode/build.spec)
      if [[ ${pkgsrc_url:(-1)} != "/" ]]; then
        pkgsrc_url=$pkgsrc_url/
      fi
      local pkgsrc_ver=$(echo "${pkgsrc_url}" | cut -d '/' -f5)
      local gccver=$(echo "${pkgsrc_url}" | cut -d '/' -f6)

      local cache_dir=$MG_CACHE_DIR/pkgsrc/$pkgsrc_ver/$gccver/All
      local dest_dir=build/pkgsrc/${pkgsrc_ver}/${gccver}/All
      mkdir -p $cache_dir
      mkdir -p $dest_dir

      if [[ ! -f $dest_dir/../SHA512.bz2 ]]; then
        echo "# get ${pkgsrc_url}/../SHA512.bz2"
        if ${CURL} -S -o $cache_dir/../SHA512.bz2 ${pkgsrc_url}/../SHA512.bz2; then
          $CP_LINK $cache_dir/../SHA512.bz2 $dest_dir/../SHA512.bz2
        elif [[ ! -f $dest_dir/md5sums.txt ]]; then
          echo "# get ${pkgsrc_url}md5sums.txt"
          ${CURL} -S -o $cache_dir/md5sums.txt ${pkgsrc_url}md5sums.txt
          $CP_LINK $cache_dir/md5sums.txt $dest_dir/md5sums.txt
        fi
      fi

      for file in $(cat $(dirname ${dataset})/pkgsrc); do
        if [[ -f $dest_dir/$file.tgz ]]; then
          true # pass through
        else
          if [[ ! -f $cache_dir/${file}.tgz ]]; then
            echo "# get ${pkgsrc_url}${file}.tgz"
            ${CURL} -S -o $cache_dir/$file.tgz ${pkgsrc_url}/${file}.tgz

            if [[ -f $cache_dir/../SHA512.bz2 ]]; then
              local correct_sha512=$(bzcat ${cache_dir}/../SHA512.bz2 | grep "/${file}.tgz)" | cut -d' ' -f4)
              local actual_sha512=$(openssl dgst -sha512 < $cache_dir/$file.tgz | awk '{print $NF}')
              if [[ $correct_sha512 != $actual_sha512 ]]; then
                rm $cache_dir/$file.tgz
                fatal "SHA512 check failure on $cache_dir/$file.tgz (actual $actual_sha512, from SHA512.bz2 $correct_sha512)"
              fi
            elif [[ -f $cache_dir/md5sums.txt ]]; then
              local correct_md5=$(grep $file $cache_dir/md5sums.txt | cut -d ' ' -f1)
              local actual_md5=$(openssl dgst -md5 < $cache_dir/$file.tgz | awk '{print $NF}')
              if [[ $correct_md5 != $actual_md5 ]]; then
                rm $cache_dir/$file.tgz
                fatal "md5 check failure on $cache_dir/$file.tgz (actual $actual_md5, from md5sums $correct_md5)"
              fi
            fi
          else
            echo "# have $cache_dir/$file.tgz"
          fi
          $CP_LINK $cache_dir/$file.tgz $dest_dir/
        fi
      done
    done

    set +o xtrace

  fi
}




#---- mainline

trap 'errexit $? $LINENO' EXIT

# Can be a target name to tell 'configure' to (a) limit prep to just that
# target and (b) pre-load "bits/" with pre-built dependent target bits.
# If empty it means that we are configuring for a full build.
TARGET=
REGENERATE='false'
MG_NODE=$(which node)


if [[ "$1" == "--help" ]]; then
  print_help
fi
while getopts "b:B:hrft:c:n:" opt; do
    case "$opt" in
        b) BRANCH=$OPTARG ;;
        B) TRY_BRANCH=$OPTARG ;;
        h) print_help ;;
        r)
            REGENERATE='true'
            ;;
        n) MG_NODE=${OPTARG} ;;
        t) TARGET=${OPTARG} ;;
        c) MG_CACHE_DIR=${OPTARG} ;;
        ?) fatal "unknown option: $opt" ;;
    esac
done
shift $((OPTIND-1))


# Pre-condition: must have node >=0.6 first on path (see RELENG-266).
echo "Ensure have a 'node' v0.6."
NODE_VERSION=$($MG_NODE --version | awk 'BEGIN{ FS="." } { print $2 }')
if [[ $NODE_VERSION -lt 6 ]]; then
    fatal "Incorrect node version, '${NODE_VERSION}'. MG needs a node v0.6 or later (currently requiring v0.6 or v0.8). Either put a node v0.6 first on your PATH or use the '-n NODE_EXE' configure option."
fi
JSON="$MG_NODE $ROOT/tools/json"

# '-r' regenerate early out.
if [[ "$REGENERATE" == 'true' ]]; then
    gen_config
    exit 0
fi


# Else we are doing a full configure for a fresh build. Start fresh:
mkdir -p bits
touch bits/config.mk
make distclean


if [[ ! -z "$TARGET" ]]; then
    flush_bits_cache
    if [[ "$TARGET" == "all-except-platform" ]]; then
        preload_bits "platform" "$BRANCH" "$TRY_BRANCH"
        TARGETS=$(${MG_NODE} -e 'fs=require("fs"); c=fs.readFileSync("targets.json"); console.log(Object.keys(JSON.parse(c)).join("\n"))' | grep -v '^platform')
        for targ in $TARGETS; do
            get_target_repos $targ
            for dep in `cat targets.json | $JSON $targ.deps | $JSON -a`; do
                preload_bits $dep "$BRANCH" "$TRY_BRANCH"
            done
        done
    else
        # Validate target.
        TARGETS=$TARGET
        if [[ -z "$(cat targets.json | $JSON $TARGET)" ]]; then
            fatal "Unknown target: $TARGET"
        fi
        get_target_repos $TARGET
        for dep in `cat targets.json | $JSON $TARGET.deps | $JSON -a`; do
            preload_bits $dep "$BRANCH" "$TRY_BRANCH"
        done
    fi
else
    TARGETS=$(${MG_NODE} -e 'fs=require("fs"); c=fs.readFileSync("targets.json"); console.log(Object.keys(JSON.parse(c)).join("\n"))')
    for targ in $TARGETS; do
        get_target_repos $targ
    done
fi

# "all" is a special target with deps to always preload.
# I.e. for which "make all" doesn't build it.
for dep in `cat targets.json | $JSON all.deps | $JSON -a`; do
    preload_bits $dep "$BRANCH" "$TRY_BRANCH"
done

#get_pkgsrc

gen_config
